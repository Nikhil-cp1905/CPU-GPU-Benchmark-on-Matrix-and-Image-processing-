<html><head><meta charset='utf-8'><title>CPU vs GPU Benchmark Report</title></head><body><h1>CPU vs GPU Benchmark Report</h1>
<p>Generated: 2025-10-28T19:42:29.856028</p>
<h2>Matrix multiplication: time vs size</h2>
<img src="../plots/matrix_time_vs_size.png" style="max-width:900px">
<h3>Speedup (CPU/GPU)</h3>
<img src="../plots/matrix_speedup.png" style="max-width:900px">
<h3>GPU transfer vs compute breakdown</h3>
<img src="../plots/matrix_gpu_breakdown.png" style="max-width:900px">
<h2>Image processing: time vs size</h2>
<img src="../plots/image_time_vs_size.png" style="max-width:900px">
<h3>Image speedup (CPU/GPU)</h3>
<img src="../plots/image_speedup.png" style="max-width:900px">
<h2>GPU utilization timeline</h2>
<img src="../plots/gpu_util_time.png" style="max-width:900px">
<h2>Textual analysis</h2>
<pre>CPU vs GPU Benchmark â€” concise analysis

Files used:

 - matrix_results.csv
 - image_results.csv
 - gpu_log.csv

Key findings (answer depends on your CSVs):

- Small matrices/images: the CPU may be faster due to host<->device overhead and BLAS multi-threading on CPU.

- Medium-to-large sizes: GPU typically outperforms because of massive parallelism; speedup grows with problem size.

- Transfer vs compute: if transfer bars are large relative to compute, consider batching or pinned memory and streams.

- GPU utilization: high sustained utilization indicates compute-bound workload (GPU advantage). Low utilization + long runtime suggests I/O or small kernels.


Recommended next steps:

 - Report median and 95% CI for each measurement (we used medians here)
 - Show both compute-only (device-resident) and end-to-end times (including transfers)
 - Try batched GEMM or asynchronous streams to hide transfer time for real workloads.
</pre><hr><p>End of report</p></body></html>